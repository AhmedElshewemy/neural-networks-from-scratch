{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjKixSLxTDH50sinmlAtre"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVfvbJDRD_di","executionInfo":{"status":"ok","timestamp":1711982185829,"user_tz":-120,"elapsed":34726,"user":{"displayName":"Elshewemy","userId":"16546093105872884942"}},"outputId":"0d4be511-c9db-4419-c530-547a100537d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","77/77 [==============================] - 4s 19ms/step - loss: 1.4286 - accuracy: 0.6946 - val_loss: 0.5677 - val_accuracy: 0.9085\n","Epoch 2/20\n","77/77 [==============================] - 1s 9ms/step - loss: 0.3280 - accuracy: 0.9464 - val_loss: 0.2669 - val_accuracy: 0.9346\n","Epoch 3/20\n","77/77 [==============================] - 1s 13ms/step - loss: 0.1876 - accuracy: 0.9575 - val_loss: 0.2263 - val_accuracy: 0.9346\n","Epoch 4/20\n","77/77 [==============================] - 1s 11ms/step - loss: 0.1451 - accuracy: 0.9644 - val_loss: 0.1788 - val_accuracy: 0.9444\n","Epoch 5/20\n","77/77 [==============================] - 1s 10ms/step - loss: 0.1179 - accuracy: 0.9681 - val_loss: 0.1536 - val_accuracy: 0.9592\n","Epoch 6/20\n","77/77 [==============================] - 1s 12ms/step - loss: 0.1011 - accuracy: 0.9763 - val_loss: 0.1462 - val_accuracy: 0.9608\n","Epoch 7/20\n","77/77 [==============================] - 1s 10ms/step - loss: 0.0876 - accuracy: 0.9759 - val_loss: 0.1213 - val_accuracy: 0.9706\n","Epoch 8/20\n","77/77 [==============================] - 1s 13ms/step - loss: 0.0828 - accuracy: 0.9767 - val_loss: 0.1337 - val_accuracy: 0.9739\n","Epoch 9/20\n","77/77 [==============================] - 1s 12ms/step - loss: 0.0701 - accuracy: 0.9828 - val_loss: 0.1110 - val_accuracy: 0.9673\n","Epoch 10/20\n","77/77 [==============================] - 1s 15ms/step - loss: 0.0621 - accuracy: 0.9857 - val_loss: 0.1045 - val_accuracy: 0.9722\n","Epoch 11/20\n","77/77 [==============================] - 1s 13ms/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 0.1126 - val_accuracy: 0.9690\n","Epoch 12/20\n","77/77 [==============================] - 1s 16ms/step - loss: 0.0498 - accuracy: 0.9898 - val_loss: 0.1048 - val_accuracy: 0.9706\n","Epoch 13/20\n","77/77 [==============================] - 1s 16ms/step - loss: 0.0449 - accuracy: 0.9894 - val_loss: 0.0998 - val_accuracy: 0.9706\n","Epoch 14/20\n","77/77 [==============================] - 1s 12ms/step - loss: 0.0416 - accuracy: 0.9886 - val_loss: 0.1057 - val_accuracy: 0.9755\n","Epoch 15/20\n","77/77 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9922 - val_loss: 0.1003 - val_accuracy: 0.9771\n","Epoch 16/20\n","77/77 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9943 - val_loss: 0.0943 - val_accuracy: 0.9788\n","Epoch 17/20\n","77/77 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9935 - val_loss: 0.0886 - val_accuracy: 0.9788\n","Epoch 18/20\n","77/77 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9959 - val_loss: 0.0932 - val_accuracy: 0.9739\n","Epoch 19/20\n","77/77 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9967 - val_loss: 0.0925 - val_accuracy: 0.9771\n","Epoch 20/20\n","77/77 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9963 - val_loss: 0.0860 - val_accuracy: 0.9804\n","24/24 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9752\n","Test Loss: 0.0733814686536789, Test Accuracy: 0.9751634001731873\n"]}],"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","\n","# Load dataset\n","data = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra\", delimiter=\",\")\n","\n","# Shuffle the data\n","np.random.shuffle(data)\n","\n","# Split data into features and labels\n","X = data[:, :-1]\n","y = data[:, -1]\n","\n","# Normalize the features\n","X /= 16\n","\n","# One-hot encode the labels\n","y_one_hot = to_categorical(y)\n","\n","# Split data into train and test sets\n","split = int(0.8 * len(X))\n","X_train, X_test = X[:split], X[split:]\n","y_train, y_test = y_one_hot[:split], y_one_hot[split:]\n","\n","# Define the neural network architecture\n","model = Sequential([\n","    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n","    Dense(64, activation=\"relu\"),\n","    Dense(10, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n","\n","# Evaluate on test set\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"]}]}