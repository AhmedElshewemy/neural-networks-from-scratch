{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMz5YgDNw3tHNqjPkwyhQQQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"u2tf6S2lFvkU"},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import load_digits\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","digits = load_digits()\n","\n","# Preprocess the data\n","X = digits.data\n","y = digits.target\n","\n","# Normalize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","source":["class NeuralNetwork:\n","    def __init__(self, input_size, hidden_size, output_size):\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n","        self.b1 = np.zeros((1, self.hidden_size))\n","        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n","        self.b2 = np.zeros((1, self.output_size))\n","        self.loss_history = []\n","        self.accuracy_history = []\n","\n","    def forward(self, X):\n","        self.z1 = np.dot(X, self.W1) + self.b1\n","        self.a1 = np.tanh(self.z1)\n","        self.z2 = np.dot(self.a1, self.W2) + self.b2\n","        exp_scores = np.exp(self.z2)\n","        self.probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n","\n","    def backward(self, X, y, learning_rate=0.01):\n","        m = X.shape[0]\n","        delta3 = self.probs\n","        delta3[range(m), y] -= 1\n","        dW2 = np.dot(self.a1.T, delta3)\n","        db2 = np.sum(delta3, axis=0, keepdims=True)\n","        delta2 = np.dot(delta3, self.W2.T) * (1 - np.power(self.a1, 2))\n","        dW1 = np.dot(X.T, delta2)\n","        db1 = np.sum(delta2, axis=0)\n","\n","        # Update weights and biases\n","        self.W1 -= learning_rate * dW1\n","        self.b1 -= learning_rate * db1\n","        self.W2 -= learning_rate * dW2\n","        self.b2 -= learning_rate * db2\n","\n","    def train(self, X, y, epochs=2000):\n","        for i in range(epochs):\n","            self.forward(X)\n","            self.backward(X, y)\n","            # Calculate accuracy and loss\n","            predictions = self.predict(X)\n","            accuracy = np.mean(predictions == y)\n","            loss = self.calculate_loss(X, y)\n","            self.accuracy_history.append(accuracy)\n","            self.loss_history.append(loss)\n","            if i % 10 == 0:\n","                print(f\"Epoch {i}: Accuracy = {accuracy}, Loss = {loss}\")\n","\n","    def predict(self, X):\n","        self.forward(X)\n","        return np.argmax(self.probs, axis=1)\n","\n","    def calculate_loss(self, X, y):\n","        m = X.shape[0]\n","        correct_logprobs = -np.log(self.probs[range(m), y])\n","        data_loss = np.sum(correct_logprobs)\n","        return 1./m * data_loss\n","# Initialize and train the model\n","input_size = X_train.shape[1]\n","hidden_size = 100\n","output_size = len(np.unique(y_train))\n","model = NeuralNetwork(input_size, hidden_size, output_size)\n","model.train(X_train, y_train,epochs=100)\n","\n","# Evaluate the model\n","predictions = model.predict(X_test)\n","accuracy = np.mean(predictions == y_test)\n","print(\"Final Accuracy:\", accuracy)"],"metadata":{"id":"v1waS7_dH0t6","executionInfo":{"status":"ok","timestamp":1714664328558,"user_tz":-180,"elapsed":2668,"user":{"displayName":"Elshewemy","userId":"16546093105872884942"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba224619-0172-49a0-b15f-92579b88ef7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: Accuracy = 0.7814892136395268, Loss = 3.611505362555385\n","Epoch 10: Accuracy = 0.9951287404314544, Loss = 0.033585369931262654\n","Epoch 20: Accuracy = 0.9993041057759221, Loss = 0.00425208228445983\n","Epoch 30: Accuracy = 1.0, Loss = 0.0010759466062494148\n","Epoch 40: Accuracy = 1.0, Loss = 0.0007389959980442664\n","Epoch 50: Accuracy = 1.0, Loss = 0.0005741542455718919\n","Epoch 60: Accuracy = 1.0, Loss = 0.00047346626713515864\n","Epoch 70: Accuracy = 1.0, Loss = 0.00040480168724616947\n","Epoch 80: Accuracy = 1.0, Loss = 0.00035464509757042516\n","Epoch 90: Accuracy = 1.0, Loss = 0.00031622815347374326\n","Final Accuracy: 0.9416666666666667\n"]}]},{"cell_type":"code","source":["y_train.shape"],"metadata":{"id":"vxxKMjLEm4xi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714664738575,"user_tz":-180,"elapsed":4,"user":{"displayName":"Elshewemy","userId":"16546093105872884942"}},"outputId":"e3f65e45-05d1-4c55-eecf-f782e77b6c46"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1437,)"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":[],"metadata":{"id":"iydbKZ2qm44v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.probs.shape\n"],"metadata":{"id":"Evy5My5Bm47I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714664712371,"user_tz":-180,"elapsed":6,"user":{"displayName":"Elshewemy","userId":"16546093105872884942"}},"outputId":"a24e3687-bcdb-4ad5-a955-607e6617dbdf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(360, 10)"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["y_trai"],"metadata":{"id":"jDht4cJ9m49S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zSPHX9KLm4_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4MckCASFIC_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NeuralNetwork:\n","    def __init__(self, input_size, hidden_size, output_size):\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n","        self.b1 = np.zeros((1, self.hidden_size))\n","        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n","        self.b2 = np.zeros((1, self.output_size))\n","        self.loss_history = []\n","        self.accuracy_history = []\n","\n","    def forward(self, X):\n","        self.z1 = np.dot(X, self.W1) + self.b1\n","        self.a1 = np.tanh(self.z1)\n","        self.z2 = np.dot(self.a1, self.W2) + self.b2\n","        exp_scores = np.exp(self.z2)\n","        self.probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n","\n","    def backward(self, X, y, learning_rate=0.01):\n","        m = X.shape[0]\n","        delta3 = self.probs\n","        delta3[range(m), y] -= 1\n","        dW2 = np.dot(self.a1.T, delta3)\n","        db2 = np.sum(delta3, axis=0, keepdims=True)\n","        delta2 = np.dot(delta3, self.W2.T) * self.a1*(1 - np.power(self.a1, 2))\n","        dW1 = np.dot(X.T, delta2)\n","        db1 = np.sum(delta2, axis=0)\n","\n","        # Update weights and biases\n","        self.W1 -= learning_rate * dW1\n","        self.b1 -= learning_rate * db1\n","        self.W2 -= learning_rate * dW2\n","        self.b2 -= learning_rate * db2\n","\n","    def train(self, X, y, epochs=2000):\n","        for i in range(epochs):\n","            self.forward(X)\n","            self.backward(X, y)\n","            # Calculate accuracy and loss\n","            predictions = self.predict(X)\n","            accuracy = np.mean(predictions == y)\n","            loss = self.calculate_loss(X, y)\n","            self.accuracy_history.append(accuracy)\n","            self.loss_history.append(loss)\n","            if i % 10 == 0:\n","                print(f\"Epoch {i}: Accuracy = {accuracy}, Loss = {loss}\")\n","\n","    def predict(self, X):\n","        self.forward(X)\n","        return np.argmax(self.probs, axis=1)\n","\n","    def calculate_loss(self, X, y):\n","        m = X.shape[0]\n","        correct_logprobs = -y*np.log(self.probs[range(m), y])\n","        data_loss = np.sum(correct_logprobs)\n","        return 1./m * data_loss\n","# Initialize and train the model\n","input_size = X_train.shape[1]\n","hidden_size = 100\n","output_size = len(np.unique(y_train))\n","model = NeuralNetwork(input_size, hidden_size, output_size)\n","model.train(X_train, y_train,epochs=100)\n","\n","# Evaluate the model\n","predictions = model.predict(X_test)\n","accuracy = np.mean(predictions == y_test)\n","print(\"Final Accuracy:\", accuracy)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1714663837452,"user_tz":-180,"elapsed":2906,"user":{"displayName":"Elshewemy","userId":"16546093105872884942"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"bf_TSchY5gsV","outputId":"0c190056-cc6c-46ac-c397-9501b5bd8b6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: Accuracy = 0.5935977731384829, Loss = 46.44187542285117\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-35-7a54413b02b4>:17: RuntimeWarning: overflow encountered in exp\n","  exp_scores = np.exp(self.z2)\n","<ipython-input-35-7a54413b02b4>:18: RuntimeWarning: invalid value encountered in divide\n","  self.probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n","<ipython-input-35-7a54413b02b4>:55: RuntimeWarning: divide by zero encountered in log\n","  correct_logprobs = -y*np.log(self.probs[range(m), y])\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 20: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 30: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 40: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 50: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 60: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 70: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 80: Accuracy = 0.10090466249130133, Loss = nan\n","Epoch 90: Accuracy = 0.10090466249130133, Loss = nan\n","Final Accuracy: 0.09166666666666666\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"o8VFn4H_5gOi"}}]}